{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVAPtMDTYvRD"
   },
   "source": [
    "# Depression and Anxiety classification with ERPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conceptual replication of the study by [Cavanagh et al. (2019)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6515849/) on own dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcABdbTciWqA"
   },
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1677517783528,
     "user": {
      "displayName": "Anna Grabowska",
      "userId": "15734344613010880864"
     },
     "user_tz": -60
    },
    "id": "N_cSZrE3hRG1"
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import mne\n",
    "import copy\n",
    "import glob\n",
    "import array\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import seaborn as sns\n",
    "import scipy.io as sio\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score, RepeatedStratifiedKFold\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from autoreject import AutoReject\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "from mne.decoding import CSP\n",
    "from mne.preprocessing import Xdawn\n",
    "from mne.decoding import Vectorizer\n",
    "from mne.decoding import UnsupervisedSpatialFilter\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "# parameters for plotting\n",
    "plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constatnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "signal_frequency = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wDt-UDhFqu0g"
   },
   "source": [
    "## Load EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_pickle('data/sonata_data/sonata_data_GNG_autoreject_freq_short.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1677518482887,
     "user": {
      "displayName": "Anna Grabowska",
      "userId": "15734344613010880864"
     },
     "user_tz": -60
    },
    "id": "99n0TtUK9ksT",
    "outputId": "f3ba7a7e-1df9-40f7-8cb7-531dc5568a22"
   },
   "outputs": [],
   "source": [
    "dep = data_df[(data_df['BDI'] > 13) & (data_df['STAI'] > 41)]\n",
    "ctrl_dep = data_df[(data_df['BDI'] <= 13) & (data_df['STAI'] > 41)]\n",
    "anx = data_df[(data_df['BDI'] <= 13) & (data_df['STAI'] > 42)]\n",
    "ctrl_anx = data_df[(data_df['BDI'] <= 13) & (data_df['STAI'] < 41)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating p-value with permutation test from sci-kit learn\n",
    "def calculate_p_permutations(estimator, X, y, cv=5, n_permutations=1000, n_jobs=1):\n",
    "\n",
    "    score_, perm_scores_, pvalue_ = permutation_test_score(\n",
    "        estimator, X, y, cv=cv, n_permutations=n_permutations, n_jobs=n_jobs\n",
    "    )\n",
    "\n",
    "    # summarize\n",
    "    print(f\"     The permutation P-value is = {pvalue_:.4f}\")\n",
    "    print(f\"     The permutation score is = {score_:.4f}\\n\")\n",
    "\n",
    "    return score_, pvalue_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "5ES-E98N1UR5"
   },
   "outputs": [],
   "source": [
    "def evaluate_GS_model(\n",
    "    pipe,\n",
    "    X_train, \n",
    "    y_train, \n",
    "    X_test, \n",
    "    y_test, \n",
    "    classifier_params,\n",
    "    pipeline_name,\n",
    "    cv=StratifiedKFold(n_splits=5),\n",
    "    predict_test = True,\n",
    "    predict_train = True,\n",
    "    ):\n",
    "    \n",
    "    # define grid search\n",
    "    grid_search_model = GridSearchCV(\n",
    "        pipe,\n",
    "        classifier_params,\n",
    "        cv=cv,\n",
    "        scoring={\"roc_auc\", \"balanced_accuracy\", \"precision\", \"recall\"},\n",
    "        refit=\"balanced_accuracy\",\n",
    "        return_train_score=True,\n",
    "        verbose=10,\n",
    "        n_jobs=1,\n",
    "        \n",
    "    )\n",
    "\n",
    "    # fit model\n",
    "    grid_search_model.fit(X_train, y_train)\n",
    "\n",
    "    # predict train data\n",
    "    y_train_pred = grid_search_model.predict(X_train) if predict_train is True else None\n",
    "    train_score = roc_auc_score(y_train, y_train_pred) if predict_train is True else None \n",
    "\n",
    "    # extract mean cv scores\n",
    "    mean_cv_score = grid_search_model.best_score_\n",
    "    cv_results_df = pd.DataFrame(grid_search_model.cv_results_).iloc[[grid_search_model.best_index_]]\n",
    "    cv_splits_scores_df = cv_results_df.filter(regex=r\"split\\d*_test_roc_auc\").reset_index(drop=True) \n",
    "\n",
    "    metrics_results_df = cv_results_df.filter(regex=r\"mean_test_*\").reset_index(drop=True)\n",
    "    \n",
    "    # calculate p-value\n",
    "    cv_p = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    scores_, pvalue_ = calculate_p_permutations(\n",
    "            grid_search_model.best_estimator_, X_train, y_train, cv=cv_p\n",
    "        )\n",
    "\n",
    "    # save results in dataframe\n",
    "    this_result = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame({\n",
    "            \"model_name\": [pipe.steps[-1][0]],\n",
    "            \"pipeline_name\": [pipeline_name],\n",
    "            \"train score\": [train_score],\n",
    "            \"mean_cv_score\": [mean_cv_score],\n",
    "            \"best_model\": [grid_search_model.best_estimator_],\n",
    "            \"parameters\": [grid_search_model.best_params_],\n",
    "            \"pvalue\":[pvalue_],    \n",
    "            }),\n",
    "         metrics_results_df,\n",
    "        ],\n",
    "    axis=1\n",
    "    ) \n",
    "\n",
    "    return this_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RcHAwa6LOvqm"
   },
   "source": [
    "Define estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "DtsaDVEdPHXs"
   },
   "outputs": [],
   "source": [
    "svc = ('svc' , SVC())\n",
    "svc_params = dict(\n",
    "    svc__kernel=[\"linear\"],\n",
    "    svc__C=[0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    ")\n",
    "\n",
    "estimators = [\n",
    "    (svc, svc_params),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g-Hb8Rb_Ei8j"
   },
   "source": [
    "### Depression vs Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7C3WZvf1irT"
   },
   "source": [
    "#### Based on RewP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = 0.20\n",
    "tmax = 0.30\n",
    "picks = ['FCz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewp_depression_datasets = []\n",
    "\n",
    "dep_data = [np.mean(mne.filter.resample(epoch['f_good'].average().get_data(tmin=tmin, tmax=tmax, picks=picks), down=1.0)) for epoch in dep['epochs'].to_numpy()]\n",
    "ctrl_data = [np.mean(mne.filter.resample(epoch['f_good'].average().get_data(tmin=tmin, tmax=tmax,picks=picks), down=1.0)) for epoch in ctrl_dep['epochs'].to_numpy()]\n",
    "\n",
    "X_rewp = np.array(dep_data)\n",
    "X_rewp_ctrl = np.array(ctrl_data)\n",
    "\n",
    "rewp_depression_datasets = [X_rewp, X_rewp_ctrl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "vec = Vectorizer()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "\n",
    "results_dep_rewp_df = pd.DataFrame()\n",
    "\n",
    "global_params = {}\n",
    "\n",
    "X = np.concatenate([rewp_depression_datasets[0], rewp_depression_datasets[1]])\n",
    "y = np.array(len(rewp_depression_datasets[0]) * [1] +  len(rewp_depression_datasets[1]) * [0])\n",
    "\n",
    "for (estimator, params) in estimators:\n",
    "    print(f\"Rating {estimator} \\n\")\n",
    "\n",
    "    pipeline_name = \"RewP_Depression_\" + estimator[0]\n",
    "\n",
    "    clf = Pipeline([estimator])\n",
    "    classifier_params = {**global_params, **params}\n",
    "\n",
    "    # enter to grid search\n",
    "    grid_result = evaluate_GS_model(\n",
    "        clf,\n",
    "        X,\n",
    "        y,\n",
    "        [],\n",
    "        [],\n",
    "        classifier_params = classifier_params,\n",
    "        pipeline_name = pipeline_name,\n",
    "        cv=cv,\n",
    "    )\n",
    "\n",
    "    print(grid_result)\n",
    "\n",
    "    results_dep_rewp_df = pd.concat([results_dep_rewp_df, grid_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dep_rewp_df.to_pickle(f\"data/sonata_data/results/{task}/depression_rewp_erp_results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7C3WZvf1irT"
   },
   "source": [
    "#### Based on RewP and P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = 0.20\n",
    "tmax = 0.30\n",
    "picks = ['FCz']\n",
    "\n",
    "tmin_p3 = 0.3\n",
    "tmax_p3 = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewp_depression_datasets = []\n",
    "\n",
    "dep_data = [np.mean(mne.filter.resample(epoch['f_good'].average().get_data(tmin=tmin, tmax=tmax, picks=picks), down=1.0)) for epoch in dep['epochs'].to_numpy()]\n",
    "ctrl_data = [np.mean(mne.filter.resample(epoch['f_good'].average().get_data(tmin=tmin, tmax=tmax,picks=picks), down=1.0)) for epoch in ctrl_dep['epochs'].to_numpy()]\n",
    "\n",
    "dep_p3_data = [np.mean(mne.filter.resample(epoch['f_good'].average().get_data(tmin=tmin_p3, tmax=tmax_p3, picks=picks), down=1.0)) for epoch in dep['epochs'].to_numpy()]\n",
    "ctrl_p3_data = [np.mean(mne.filter.resample(epoch['f_good'].average().get_data(tmin=tmin_p3, tmax=tmax_p3,picks=picks), down=1.0)) for epoch in ctrl_dep['epochs'].to_numpy()]\n",
    "\n",
    "\n",
    "X_rewp = np.array(dep_data)\n",
    "X_rewp_ctrl = np.array(ctrl_data)\n",
    "\n",
    "X_p3 = np.array(dep_p3_data)\n",
    "X_p3_ctrl = np.array(ctrl_p3_data)\n",
    "\n",
    "X_dep = np.column_stack((X_rewp, X_p3))\n",
    "X_ctr = np.column_stack((X_rewp_ctrl, X_p3_ctrl))\n",
    "\n",
    "rewp_depression_datasets = [X_dep, X_ctr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "vec = Vectorizer()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "\n",
    "results_dep_rewp_df = pd.DataFrame()\n",
    "\n",
    "global_params = {}\n",
    "\n",
    "X = np.concatenate([rewp_depression_datasets[0], rewp_depression_datasets[1]])\n",
    "y = np.array(len(rewp_depression_datasets[0]) * [1] +  len(rewp_depression_datasets[1]) * [0])\n",
    "\n",
    "for (estimator, params) in estimators:\n",
    "    print(f\"Rating {estimator} \\n\")\n",
    "\n",
    "    pipeline_name = \"RewP_Depression_p3_control_\" + estimator[0]\n",
    "\n",
    "    clf = Pipeline([estimator])\n",
    "    classifier_params = {**global_params, **params}\n",
    "\n",
    "    # enter to grid search\n",
    "    grid_result = evaluate_GS_model(\n",
    "        clf,\n",
    "        X,\n",
    "        y,\n",
    "        [],\n",
    "        [],\n",
    "        classifier_params = classifier_params,\n",
    "        pipeline_name = pipeline_name,\n",
    "        cv=cv,\n",
    "    )\n",
    "\n",
    "    print(grid_result)\n",
    "\n",
    "    results_dep_rewp_df = pd.concat([results_dep_rewp_df, grid_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dep_rewp_df.to_pickle(f\"data/sonata_data/results/{task}/depression_rewp_erp_p3_results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdOE13g71oii"
   },
   "source": [
    "#### Based on FRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "vcTUfJ4x1oij"
   },
   "outputs": [],
   "source": [
    "tmin = 0.20\n",
    "tmax = 0.30\n",
    "picks = ['FCz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "frn_depression_datasets = []\n",
    "\n",
    "dep_data = [np.mean(mne.filter.resample(epoch['f_bad'].average().get_data(tmin=tmin, tmax=tmax, picks=picks), down=1.0)) for epoch in dep['epochs'].to_numpy()]\n",
    "ctrl_data = [np.mean(mne.filter.resample(epoch['f_bad'].average().get_data(tmin=tmin, tmax=tmax,picks=picks), down=1.0)) for epoch in ctrl_dep['epochs'].to_numpy()]\n",
    "\n",
    "X_rewp = np.array(dep_data)\n",
    "X_rewp_ctrl = np.array(ctrl_data)\n",
    "\n",
    "frn_depression_datasets = [X_rewp, X_rewp_ctrl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "vec = Vectorizer()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "\n",
    "results_dep_frn_df = pd.DataFrame()\n",
    "\n",
    "global_params = {}\n",
    "\n",
    "X = np.concatenate([frn_depression_datasets[0], frn_depression_datasets[1]])\n",
    "y = np.array(len(frn_depression_datasets[0]) * [1] +  len(frn_depression_datasets[1]) * [0])\n",
    "\n",
    "for (estimator, params) in estimators:\n",
    "    print(f\"Rating {estimator} \\n\")\n",
    "\n",
    "    pipeline_name = \"FRN_Depression_\" + estimator[0]\n",
    "\n",
    "    clf = Pipeline([estimator])\n",
    "    classifier_params = {**global_params, **params}\n",
    "\n",
    "    # enter to grid search\n",
    "    grid_result = evaluate_GS_model(\n",
    "        clf,\n",
    "        X,\n",
    "        y,\n",
    "        [],\n",
    "        [],\n",
    "        classifier_params = classifier_params,\n",
    "        pipeline_name = pipeline_name,\n",
    "        cv=cv,\n",
    "    )\n",
    "\n",
    "    print(grid_result)\n",
    "\n",
    "    results_dep_frn_df = pd.concat([results_dep_frn_df, grid_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dep_frn_df.to_pickle(f\"data/sonata_data/results/{task}/depression_frn_erp_results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdOE13g71oii"
   },
   "source": [
    "#### Based on FRN and P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "vcTUfJ4x1oij"
   },
   "outputs": [],
   "source": [
    "tmin = 0.20\n",
    "tmax = 0.30\n",
    "picks = ['FCz']\n",
    "\n",
    "tmin_p3 = 0.3\n",
    "tmax_p3 = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "frn_depression_datasets = []\n",
    "\n",
    "dep_data = [np.mean(mne.filter.resample(epoch['f_bad'].average().get_data(tmin=tmin, tmax=tmax, picks=picks), down=1.0)) for epoch in dep['epochs'].to_numpy()]\n",
    "ctrl_data = [np.mean(mne.filter.resample(epoch['f_bad'].average().get_data(tmin=tmin, tmax=tmax,picks=picks), down=1.0)) for epoch in ctrl_dep['epochs'].to_numpy()]\n",
    "\n",
    "dep_p3_data = [np.mean(mne.filter.resample(epoch['f_bad'].average().get_data(tmin=tmin_p3, tmax=tmax_p3, picks=picks), down=1.0)) for epoch in dep['epochs'].to_numpy()]\n",
    "ctrl_p3_data = [np.mean(mne.filter.resample(epoch['f_bad'].average().get_data(tmin=tmin_p3, tmax=tmax_p3,picks=picks), down=1.0)) for epoch in ctrl_dep['epochs'].to_numpy()]\n",
    "\n",
    "\n",
    "X_rewp = np.array(dep_data)\n",
    "X_rewp_ctrl = np.array(ctrl_data)\n",
    "\n",
    "X_p3 = np.array(dep_p3_data)\n",
    "X_p3_ctrl = np.array(ctrl_p3_data)\n",
    "\n",
    "X_dep = np.column_stack((X_rewp, X_p3))\n",
    "X_ctr = np.column_stack((X_rewp_ctrl, X_p3_ctrl))\n",
    "\n",
    "frn_depression_datasets = [X_dep, X_ctr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "vec = Vectorizer()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "\n",
    "results_dep_frn_df = pd.DataFrame()\n",
    "\n",
    "global_params = {}\n",
    "\n",
    "X = np.concatenate([frn_depression_datasets[0], frn_depression_datasets[1]])\n",
    "y = np.array(len(frn_depression_datasets[0]) * [1] +  len(frn_depression_datasets[1]) * [0])\n",
    "\n",
    "for (estimator, params) in estimators:\n",
    "    print(f\"Rating {estimator} \\n\")\n",
    "\n",
    "    pipeline_name = \"FRN_Depression_p3_control_\" + estimator[0]\n",
    "\n",
    "    clf = Pipeline([estimator])\n",
    "    classifier_params = {**global_params, **params}\n",
    "\n",
    "    # enter to grid search\n",
    "    grid_result = evaluate_GS_model(\n",
    "        clf,\n",
    "        X,\n",
    "        y,\n",
    "        [],\n",
    "        [],\n",
    "        classifier_params = classifier_params,\n",
    "        pipeline_name = pipeline_name,\n",
    "        cv=cv,\n",
    "    )\n",
    "\n",
    "    print(grid_result)\n",
    "\n",
    "    results_dep_frn_df = pd.concat([results_dep_frn_df, grid_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dep_frn_df.to_pickle(f\"data/sonata_data/results/{task}/depression_frn_erp_p3_results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5fwZt2kEwXU"
   },
   "source": [
    "### Anxiety vs Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OCw34QnEwXV"
   },
   "source": [
    "#### Based on RewP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = 0.20\n",
    "tmax = 0.30\n",
    "picks = ['FCz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewp_anxiety_datasets = []\n",
    "\n",
    "dep_data = [np.mean(mne.filter.resample(epoch['f_good'].average().get_data(tmin=tmin, tmax=tmax, picks=picks), down=1.0)) for epoch in anx['epochs'].to_numpy()]\n",
    "ctrl_data = [np.mean(mne.filter.resample(epoch['f_good'].average().get_data(tmin=tmin, tmax=tmax,picks=picks), down=1.0)) for epoch in ctrl_anx['epochs'].to_numpy()]\n",
    "\n",
    "X_rewp = np.array(dep_data)\n",
    "X_rewp_ctrl = np.array(ctrl_data)\n",
    "\n",
    "rewp_anxiety_datasets = [X_rewp, X_rewp_ctrl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "vec = Vectorizer()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "\n",
    "results_anx_rewp_df = pd.DataFrame()\n",
    "\n",
    "global_params = {}\n",
    "\n",
    "X = np.concatenate([rewp_anxiety_datasets[0], rewp_anxiety_datasets[1]])\n",
    "y = np.array(len(rewp_anxiety_datasets[0]) * [1] +  len(rewp_anxiety_datasets[1]) * [0])\n",
    "\n",
    "for (estimator, params) in estimators:\n",
    "    print(f\"Rating {estimator} \\n\")\n",
    "\n",
    "    pipeline_name = \"RewP_Anxiety_\" + estimator[0]\n",
    "\n",
    "    clf = Pipeline([estimator])\n",
    "    classifier_params = {**global_params, **params}\n",
    "\n",
    "    # enter to grid search\n",
    "    grid_result = evaluate_GS_model(\n",
    "        clf,\n",
    "        X,\n",
    "        y,\n",
    "        [],\n",
    "        [],\n",
    "        classifier_params = classifier_params,\n",
    "        pipeline_name = pipeline_name,\n",
    "        cv=cv,\n",
    "    )\n",
    "\n",
    "    print(grid_result)\n",
    "\n",
    "    results_anx_rewp_df = pd.concat([results_anx_rewp_df, grid_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_anx_rewp_df.to_pickle(f\"data/sonata_data/results/{task}/anxiety_rewp_erp_results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6OCw34QnEwXV"
   },
   "source": [
    "#### Based on RewP and P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmin = 0.20\n",
    "tmax = 0.30\n",
    "picks = ['FCz']\n",
    "\n",
    "tmin_p3 = 0.3\n",
    "tmax_p3 = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewp_anxiety_datasets = []\n",
    "\n",
    "dep_data = [np.mean(mne.filter.resample(epoch['f_good'].average().get_data(tmin=tmin, tmax=tmax, picks=picks), down=1.0)) for epoch in anx['epochs'].to_numpy()]\n",
    "ctrl_data = [np.mean(mne.filter.resample(epoch['f_good'].average().get_data(tmin=tmin, tmax=tmax,picks=picks), down=1.0)) for epoch in ctrl_anx['epochs'].to_numpy()]\n",
    "\n",
    "dep_p3_data = [np.mean(mne.filter.resample(epoch['f_good'].average().get_data(tmin=tmin_p3, tmax=tmax_p3, picks=picks), down=1.0)) for epoch in anx['epochs'].to_numpy()]\n",
    "ctrl_p3_data = [np.mean(mne.filter.resample(epoch['f_good'].average().get_data(tmin=tmin_p3, tmax=tmax_p3,picks=picks), down=1.0)) for epoch in ctrl_anx['epochs'].to_numpy()]\n",
    "\n",
    "\n",
    "X_rewp = np.array(dep_data)\n",
    "X_rewp_ctrl = np.array(ctrl_data)\n",
    "\n",
    "X_p3 = np.array(dep_p3_data)\n",
    "X_p3_ctrl = np.array(ctrl_p3_data)\n",
    "\n",
    "X_dep = np.column_stack((X_rewp, X_p3))\n",
    "X_ctr = np.column_stack((X_rewp_ctrl, X_p3_ctrl))\n",
    "\n",
    "rewp_anxiety_datasets = [X_dep, X_ctr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "vec = Vectorizer()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "\n",
    "results_anx_rewp_df = pd.DataFrame()\n",
    "\n",
    "global_params = {}\n",
    "\n",
    "X = np.concatenate([rewp_anxiety_datasets[0], rewp_anxiety_datasets[1]])\n",
    "y = np.array(len(rewp_anxiety_datasets[0]) * [1] +  len(rewp_anxiety_datasets[1]) * [0])\n",
    "\n",
    "for (estimator, params) in estimators:\n",
    "    print(f\"Rating {estimator} \\n\")\n",
    "\n",
    "    pipeline_name = \"RewP_Anxiety_p3_control_\" + estimator[0]\n",
    "\n",
    "    clf = Pipeline([estimator])\n",
    "    classifier_params = {**global_params, **params}\n",
    "\n",
    "    # enter to grid search\n",
    "    grid_result = evaluate_GS_model(\n",
    "        clf,\n",
    "        X,\n",
    "        y,\n",
    "        [],\n",
    "        [],\n",
    "        classifier_params = classifier_params,\n",
    "        pipeline_name = pipeline_name,\n",
    "        cv=cv,\n",
    "    )\n",
    "\n",
    "    print(grid_result)\n",
    "\n",
    "    results_anx_rewp_df = pd.concat([results_anx_rewp_df, grid_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_anx_rewp_df.to_pickle(f\"data/sonata_data/results/{task}/anxiety_rewp_erp_results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYZ2N89QEwXW"
   },
   "source": [
    "#### Based on FRN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "oc3KbAaiorwd"
   },
   "outputs": [],
   "source": [
    "tmin = 0.20\n",
    "tmax = 0.30\n",
    "picks = ['FCz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "frn_anxiety_datasets = []\n",
    "\n",
    "dep_data = [np.mean(mne.filter.resample(epoch['f_bad'].average().get_data(tmin=tmin, tmax=tmax, picks=picks), down=1.0)) for epoch in anx['epochs'].to_numpy()]\n",
    "ctrl_data = [np.mean(mne.filter.resample(epoch['f_bad'].average().get_data(tmin=tmin, tmax=tmax,picks=picks), down=1.0)) for epoch in ctrl_anx['epochs'].to_numpy()]\n",
    "\n",
    "X_rewp = np.array(dep_data)\n",
    "X_rewp_ctrl = np.array(ctrl_data)\n",
    "\n",
    "frn_anxiety_datasets = [X_rewp, X_rewp_ctrl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "vec = Vectorizer()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "\n",
    "results_anx_frn_df = pd.DataFrame()\n",
    "\n",
    "global_params = {}\n",
    "\n",
    "X = np.concatenate([frn_anxiety_datasets[0], frn_anxiety_datasets[1]])\n",
    "y = np.array(len(frn_anxiety_datasets[0]) * [1] +  len(frn_anxiety_datasets[1]) * [0])\n",
    "\n",
    "for (estimator, params) in estimators:\n",
    "    print(f\"Rating {estimator} \\n\")\n",
    "\n",
    "    pipeline_name = \"FRN_Depression_p3_control_\" + estimator[0]\n",
    "\n",
    "    clf = Pipeline([estimator])\n",
    "    classifier_params = {**global_params, **params}\n",
    "\n",
    "    # enter to grid search\n",
    "    grid_result = evaluate_GS_model(\n",
    "        clf,\n",
    "        X,\n",
    "        y,\n",
    "        [],\n",
    "        [],\n",
    "        classifier_params = classifier_params,\n",
    "        pipeline_name = pipeline_name,\n",
    "        cv=cv,\n",
    "    )\n",
    "\n",
    "    print(grid_result)\n",
    "\n",
    "    results_anx_frn_df = pd.concat([results_anx_frn_df, grid_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_anx_frn_df.to_pickle(f\"data/sonata_data/results/{task}/anxiety_frn_erp_results.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYZ2N89QEwXW"
   },
   "source": [
    "#### Based on FRN and P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "oc3KbAaiorwd"
   },
   "outputs": [],
   "source": [
    "tmin = 0.20\n",
    "tmax = 0.30\n",
    "picks = ['FCz']\n",
    "\n",
    "tmin_p3 = 0.3\n",
    "tmax_p3 = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "frn_anxiety_datasets = []\n",
    "\n",
    "dep_data = [np.mean(mne.filter.resample(epoch['f_bad'].average().get_data(tmin=tmin, tmax=tmax, picks=picks), down=1.0)) for epoch in anx['epochs'].to_numpy()]\n",
    "ctrl_data = [np.mean(mne.filter.resample(epoch['f_bad'].average().get_data(tmin=tmin, tmax=tmax,picks=picks), down=1.0)) for epoch in ctrl_anx['epochs'].to_numpy()]\n",
    "\n",
    "dep_p3_data = [np.mean(mne.filter.resample(epoch['f_bad'].average().get_data(tmin=tmin_p3, tmax=tmax_p3, picks=picks), down=1.0)) for epoch in anx['epochs'].to_numpy()]\n",
    "ctrl_p3_data = [np.mean(mne.filter.resample(epoch['f_bad'].average().get_data(tmin=tmin_p3, tmax=tmax_p3,picks=picks), down=1.0)) for epoch in ctrl_anx['epochs'].to_numpy()]\n",
    "\n",
    "\n",
    "X_rewp = np.array(dep_data)\n",
    "X_rewp_ctrl = np.array(ctrl_data)\n",
    "\n",
    "X_p3 = np.array(dep_p3_data)\n",
    "X_p3_ctrl = np.array(ctrl_p3_data)\n",
    "\n",
    "X_dep = np.column_stack((X_rewp, X_p3))\n",
    "X_ctr = np.column_stack((X_rewp_ctrl, X_p3_ctrl))\n",
    "\n",
    "frn_anxiety_datasets = [X_dep, X_ctr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "\n",
    "vec = Vectorizer()\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=random_state)\n",
    "\n",
    "results_anx_frn_df = pd.DataFrame()\n",
    "\n",
    "global_params = {}\n",
    "\n",
    "X = np.concatenate([frn_anxiety_datasets[0], frn_anxiety_datasets[1]])\n",
    "y = np.array(len(frn_anxiety_datasets[0]) * [1] +  len(frn_anxiety_datasets[1]) * [0])\n",
    "\n",
    "for (estimator, params) in estimators:\n",
    "    print(f\"Rating {estimator} \\n\")\n",
    "\n",
    "    pipeline_name = \"FRN_Depression_p3_control_\" + estimator[0]\n",
    "\n",
    "    clf = Pipeline([estimator])\n",
    "    classifier_params = {**global_params, **params}\n",
    "\n",
    "    # enter to grid search\n",
    "    grid_result = evaluate_GS_model(\n",
    "        clf,\n",
    "        X,\n",
    "        y,\n",
    "        [],\n",
    "        [],\n",
    "        classifier_params = classifier_params,\n",
    "        pipeline_name = pipeline_name,\n",
    "        cv=cv,\n",
    "    )\n",
    "\n",
    "    print(grid_result)\n",
    "\n",
    "    results_anx_frn_df = pd.concat([results_anx_frn_df, grid_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_anx_frn_df.to_pickle(f\"data/sonata_data/results/{task}/anxiety_frn_erp_p3_results.pkl\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "74g2chqQWa48",
    "3irne7dXaoIt"
   ],
   "name": "",
   "provenance": [
    {
     "file_id": "13OESwog1Uwt1WAcNW9QEaphoYxPyNplr",
     "timestamp": 1677327376830
    }
   ],
   "toc_visible": true,
   "version": ""
  },
  "kernelspec": {
   "display_name": "bluish",
   "language": "python",
   "name": "bluish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
